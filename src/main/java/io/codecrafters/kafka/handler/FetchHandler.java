package io.codecrafters.kafka.handler;

import io.codecrafters.kafka.common.Topic;
import io.codecrafters.kafka.protocol.FetchRequestParser;
import io.codecrafters.kafka.protocol.FetchResponseBuilder;
import io.codecrafters.kafka.protocol.KafkaRequest;
import io.codecrafters.kafka.protocol.KafkaResponse;
import io.codecrafters.kafka.storage.TopicLogReader;
import io.codecrafters.kafka.storage.PartitionLogReader;

import java.nio.ByteBuffer;
import java.util.Arrays;
import java.util.List;
import java.util.Map;

public class FetchHandler implements RequestHandler {

    private final TopicLogReader topicLogReader;
    private final PartitionLogReader partitionLogReader;

    public FetchHandler(String dataLogPath, String logFileName) {
        this.topicLogReader = new TopicLogReader(dataLogPath + "/__cluster_metadata-0", logFileName);
        this.partitionLogReader = new PartitionLogReader(dataLogPath, logFileName);
    }

    @Override
    public short getApiKey() {
        return 1;
    }

    @Override
    public KafkaResponse handle(KafkaRequest request) {
        ByteBuffer buffer = request.getRawBuffer();
        List<FetchRequestParser.FetchTopic> requestedTopics;

        try {
            requestedTopics = FetchRequestParser.parseTopics(buffer);
            System.out.println("Parsed topics count: " + requestedTopics.size());
        } catch (Exception e) {
            System.err.println("Error parsing fetch request: " + e.getMessage());
            e.printStackTrace();
            return handleEmptyRequest(request.getCorrelationId());
        }

        if (requestedTopics.isEmpty()) {
            System.out.println("Returning empty request response");
            return handleEmptyRequest(request.getCorrelationId());
        }

        Map<String, Topic> topicMap = topicLogReader.readTopics();

        FetchResponseBuilder builder = new FetchResponseBuilder(request.getCorrelationId());
        builder.addHeader(0, 0, 0);
        builder.startTopicsArray(requestedTopics.size());

        for (FetchRequestParser.FetchTopic fetchTopic : requestedTopics) {
            Topic topic = findTopicById(topicMap, fetchTopic.getTopicId());

            if (topic == null) {
                handleUnknownTopic(builder, fetchTopic);
            } else {
                handleTopicWithData(builder, fetchTopic, topic);
            }
        }

        builder.endResponse();
        return builder.build();
    }

    private KafkaResponse handleEmptyRequest(int correlationId) {
        KafkaResponse response = new KafkaResponse(correlationId, true);
        response.addBytes((byte) 0, 4);
        response.addBytes((byte) 0, 2);
        response.addBytes((byte) 0, 4);
        response.addByte((byte) 1);
        response.addByte((byte) 0);
        return response;
    }

    private void handleUnknownTopic(FetchResponseBuilder builder, FetchRequestParser.FetchTopic fetchTopic) {
        builder.addTopic(fetchTopic.getTopicId(), fetchTopic.getPartitions().size());

        for (FetchRequestParser.FetchPartition partition : fetchTopic.getPartitions()) {
            builder.addPartitionWithError(partition.getPartitionIndex(), 100);
        }

        builder.endTopic();
    }

    private void handleTopicWithData(FetchResponseBuilder builder, FetchRequestParser.FetchTopic fetchTopic, Topic topic) {
        builder.addTopic(fetchTopic.getTopicId(), fetchTopic.getPartitions().size());

        for (FetchRequestParser.FetchPartition partition : fetchTopic.getPartitions()) {
            String topicName = new String(topic.getTopicName());
            long fetchOffset = partition.getFetchOffset();

            System.out.println("Reading RecordBatch for topic: " + topicName + ", partition: " + partition.getPartitionIndex() + ", offset: " + fetchOffset);
            List<Byte> recordBatchBytes = partitionLogReader.readRecordBatch(topicName, partition.getPartitionIndex(), fetchOffset);
            System.out.println("RecordBatch size: " + recordBatchBytes.size());

            if (recordBatchBytes.isEmpty()) {
                builder.addEmptyPartition(partition.getPartitionIndex(), 0);
            } else {
                long highWatermark = fetchOffset + 1;
                builder.addPartitionWithRecords(partition.getPartitionIndex(), highWatermark, recordBatchBytes);
            }
        }

        builder.endTopic();
    }

    private Topic findTopicById(Map<String, Topic> topicMap, byte[] topicId) {
        for (Topic topic : topicMap.values()) {
            if (Arrays.equals(topic.getTopicId(), topicId)) {
                return topic;
            }
        }
        return null;
    }
}
